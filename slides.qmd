---
title: "Extract and classify data with LLM APIs"
subtitle: "A practical guide in R"
author: "Dylan Pieper<br/>Data & Social Scientist"
institute: "posit::conf(2025)<br/>University of Pittsburgh"
format: 
  revealjs:
    theme: [dark, custom.css]
    slide-number: true
    margin: 0.05
    width: 1200
    height: 900
    transition: slide
    background-transition: fade
    highlight-style: github-dark
    code-line-numbers: true
    code-overflow: wrap
    fig-cap-location: bottom
cache: true
---

## Dreams do come true {.fade-in}

::::: columns
::: {.column width="60%"}
::: {.fragment .zoom-in style="text-align: center;"}
![](images/llm_workflow.png){fig-alt="LLM Workflow" width="440"}
:::
:::
::: {.column width="40%"}
### LLMs make unstructured data analysis accessible {.fragment .fade-in-then-semi-out}

::: {.fragment .fade-up}
One model to process thousands of texts, documents, and images
:::
:::
:::::

## What is extraction? {auto-animate="true"}
Describe the distinct **features** of an object

::: {style="font-size: 0.8em;"}
::: columns
::: {.column width="33%"}
### Setosa
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/setosa.jpg){fig-alt="Iris setosa flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia, public domain
:::

- Smallest
- Short petals  
- Wide sepals
:::

::: {.column width="33%"}
### Virginica
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/virginica.jpg){fig-alt="Iris virginica flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia by Eric Hunt, CC-BY-SA 4.0
:::

- Medium sized
- Most variable
- Balanced proportions
:::

::: {.column width="33%"}
### Versicolor
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/versicolor.jpg){fig-alt="Iris versicolor flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia by D. Gordon E. Robertson, CC-BY-SA 3.0
:::

- Largest
- Long petals
- Narrow structure
:::
:::
:::

## What is classification? {auto-animate="true"}
Predict the distinct **category** an object belongs to

::: {style="font-size: 0.8em;"}
::: columns
::: {.column width="33%"}
### Setosa
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/setosa.jpg){fig-alt="Iris setosa flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia, public domain
:::

- <span style="color: #90EE90; font-weight: bold;">.95 setosa</span>
- .05 virginica
- .05 versicolor
:::

::: {.column width="33%"}
### Virginica
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/virginica.jpg){fig-alt="Iris virginica flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia by Eric Hunt, CC-BY-SA 4.0
:::

- .05 setosa
- <span style="color: #90EE90; font-weight: bold;">.95 virginica</span>
- .05 versicolor
:::

::: {.column width="33%"}
### Versicolor
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/versicolor.jpg){fig-alt="Iris versicolor flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia by D. Gordon E. Robertson, CC-BY-SA 3.0
:::

- .05 setosa
- .05 virginica
- <span style="color: #90EE90; font-weight: bold;">.95 versicolor</span>
:::
:::
:::

## Traditional classification

::::: columns
::: {.column width="60%"}
::: {.fragment .zoom-in style="text-align: center;"}
![](images/ml_workflow.png){fig-alt="ML Classification Workflow" width="440"}
:::
:::
::: {.column width="40%"}
### Traditional ML requires lots of data for training and testing {.fragment .fade-in-then-semi-out}

::: {.fragment .fade-up}
But it does encourage us to examine our data and the accuracy of our predictions
:::
:::
:::::

<!-- ## Traditional classification (cont'd) -->

<!-- ```{r} -->
<!-- library(tidymodels) -->

<!-- iris_classifier <- readRDS("cls_iris/iris_cls_workflow.rds") -->

<!-- new_examples <- tibble( -->
<!--   Sepal.Length = c(5.1, 6.2, 7.3, 4.8, 5.9), -->
<!--   Sepal.Width = c(3.5, 2.9, 2.8, 3.0, 3.2), -->
<!--   Petal.Length = c(1.4, 4.3, 6.3, 1.6, 4.8), -->
<!--   Petal.Width = c(0.2, 1.3, 1.8, 0.2, 1.8) -->
<!-- ) -->

<!-- iris_classifier |> -->
<!--   predict(new_data = new_examples) |> -->
<!--   bind_cols(iris_classifier %>% predict(new_data = new_examples, type = "prob")) |> -->
<!--   bind_cols(new_examples) -->
<!-- ``` -->

## What we'll cover today

::::: columns
::: {.column width="60%"}
::: {.fragment .zoom-in style="text-align: center;"}
![](https://ellmer.tidyverse.org/logo.png){fig-alt="Ellmer R package logo"}
:::
:::
::: {.column width="40%"}
### Use [`library(ellmer)`](https://ellmer.tidyverse.org/) to extract and classify data {.fragment .fade-in-then-semi-out}

::: {.fragment .fade-in-then-semi-out}
With robustness and care for delicate use cases 
:::

::: {.fragment .fade-up}
-   Flowers
-   Political speeches
-   Health symptoms
-   Crimes
:::
:::

:::::

## Setting up LLMs with ellmer
::::: columns
::: {.column width="60%"}
::: {.fragment .zoom-in data-fragment-index="1" style="text-align: center;"}
![](images/anthropic_key.jpg){fig-alt="Anthropic API key"}
Source: [Merge.dev](https://www.merge.dev/blog/anthropic-api-key)
:::
:::
::: {.column width="40%"}
::: {.fragment .fade-up data-fragment-index="2"}
::: {.incremental}
1.  Select provider (Anthropic, OpenAI, Google, etc.)
2.  Create account, add funds, and get API key
3.  Add key to R environment `usethis::edit_r_environ()`
    with `ANTHROPIC_API_KEY = "your_key"`
:::
:::
:::
:::::

## Select model
::: {.fragment .fade-up style="text-align: center;"}
![](images/anthropic_models.png){fig-alt="Anthropic model names"}

Source: [docs.anthropic.com](https://docs.anthropic.com/en/docs/about-claude/models/overview)
:::

## Getting started with ellmer

![](images/versicolor.jpg){fig-alt="Iris versicolor flower" style="height: 150px;"}

```{r}
#| echo: false
library(ellmer)
```

```{r}
#| echo: true
chat <- chat("anthropic/claude-sonnet-4-20250514")
type_flower <- type_object(
  genus    = type_string(),
  species  = type_string(),
  features = type_string("Focus on morphology"),
)
str(chat$chat_structured(
  content_image_file("images/versicolor.jpg"), type = type_flower
))
```

## Getting better with ellmer

![](images/versicolor.jpg){fig-alt="Iris versicolor flower" style="height: 150px;"}

```{r}
#| echo: true
prob <- "Probability (0.00-1.00) Iris is {{species}}"
type_flower <- type_object(
  species         = type_enum(c("setosa", "virginica", "versicolor")),
  prob_setosa     = type_number(interpolate(prob, species = "setosa")),
  prob_virginica  = type_number(interpolate(prob, species = "virginica")),
  prob_versicolor = type_number(interpolate(prob, species = "versicolor"))
)
str(chat$clone()$chat_structured(
  content_image_file("images/versicolor.jpg"), type = type_flower
))
```

## Getting upset with ellmer

![](images/setosa.jpg){fig-alt="Iris setosa flower" style="height: 150px;"}
![](images/virginica.jpg){fig-alt="Iris virginica flower" style="height: 150px;"}
![](images/versicolor.jpg){fig-alt="Iris versicolor flower" style="height: 150px;"}

```{r}
#| echo: true
parallel_chat_structured(
  chat = chat$clone(),
  prompts = list(
    content_image_file("images/setosa.jpg"),
    content_image_file("images/virginica.jpg"),
    content_image_file("images/versicolor.jpg")
  ),
  type = type_flower
)
```

## Making peace with ellmer

![](images/setosa.jpg){fig-alt="Iris setosa flower" style="height: 150px;"}
![](images/rose.jpg){fig-alt="Rose flower" style="height: 150px;"}

```{r}
#| echo: true
type_flower <- type_object(
  genus = type_enum(c( "iris", "rose")),
)
parallel_chat_structured(
  chat = chat$clone(),
  prompts = list(
    content_image_file("images/setosa.jpg"),
    content_image_file("images/rose.jpg")
  ),
  type = type_flower
)
```

## Inaugural speeches

::: {layout="[100, 50]"}
::: {.fragment .zoom-in}
![](images/inaugural_web.png){fig-alt="Trump (2025) inaugural speech webpage" style="height: 500px;"}
:::

::: {.fragment .zoom-in}
![](images/inaugural_files.png){fig-alt="Trump (2025) inaugural speech webpage"}
:::
:::

## Inaugural speeches

![](images/2013_obama.jpg){fig-alt="Obama (2013) inaugural speech" style="height: 150px;"}
![](images/2017_trump.jpg){fig-alt="Trump (2017) inaugural speech" style="height: 150px;"}
![](images/2021_biden.jpg){fig-alt="Biden (2021) inaugural speech" style="height: 150px;"}
![](images/2025_trump.jpg){fig-alt="Trump (2025) inaugural speech" style="height: 150px;"}

```{r}
#| echo: true
chat <- chat("openai/gpt-4.1")
main <- "The most prominent political {{thing}} (1-2 lowercase words)"
type_politics <- type_object(
  president   = type_string("Last name"),
  year        = type_integer(),
  leadership  = type_enum(c("democratic", "autocratic", "laissez-faire")),
  main_theme  = type_string(interpolate(main, thing = "theme")),
  main_issue  = type_string(interpolate(main, thing = "issue")),
  main_threat = type_string(interpolate(main, thing = "threat"))
)
```

## Inaugural speeches

![](images/2013_obama.jpg){fig-alt="Obama (2013) inaugural speech" style="height: 120px;"}
![](images/2017_trump.jpg){fig-alt="Trump (2017) inaugural speech" style="height: 120px;"}
![](images/2021_biden.jpg){fig-alt="Biden (2021) inaugural speech" style="height: 120px;"}
![](images/2025_trump.jpg){fig-alt="Trump (2025) inaugural speech" style="height: 120px;"}

```{r}
#| echo: true
parallel_chat_structured(
  chat,
  prompts = list.files("cls_speeches", full.names = TRUE) |>
              purrr::map(content_pdf_file),
  type = type_politics,
  include_cost = TRUE
)
```

## Health symptoms

::::: columns
::: {.column width="40%"}
::: {.fragment .fade-up style="text-align: center;"}
![](images/psoriasis.jpg){fig-alt="Psoriasis rash" style="height: 500px;"}
:::
:::

::: {.column width="60%"}
::: {.fragment .fade-up}
### Psoriasis

> "The skin on my palms and soles is thickened and has deep cracks. These cracks are painful and bleed easily."
:::
:::
:::::

## Health symptoms

Data source: [Kaggle](https://www.kaggle.com/datasets/niyarrbarman/symptom2disease/data), public domain, *n* = 1,200

```{r}
#| echo: true
symptoms <- read.csv("cls_health/Symptom2Disease.csv")
chat <- chat("openai/gpt-4.1")
type_health <- type_object(
  diagnosis   = type_enum(unique(symptoms$label)),
  uncertainty = type_number("Err on the side of caution, and
                             provide a score (0.00-1.00) of
                             uncertainty in your diagnosis.")
)
unique(symptoms$label) |> head(15)
```

## Health symptoms

```{r}
#| echo: true
oai_dat <- parallel_chat_structured(
  chat,
  prompts = as.list(symptoms$text),
  type = type_health,
  include_cost = TRUE
)
mean(oai_dat$diagnosis == symptoms$label)
mean(1 - oai_dat$uncertainty)
sum(oai_dat$cost)
```

## Crimes

::::: columns
::: {.column width="40%"}
::: {.fragment .fade-up style="text-align: center;"}
![](images/psp.jpg){fig-alt="Pennsylvania State Police"}
Source: [PA.gov](https://www.pa.gov/agencies/dgs/programs-and-services/capitol-police)
:::
:::

::: {.column width="60%"}
::: {.fragment .fade-up}
### Police reports
Descriptions of crimes

> "Criminal Conspiracy Engaging Harassment - Comm. Lewd, Threatening, Etc. Language"
:::
:::
:::::

## Crimes

Schema source: [Uniform Crime Classification Standard](https://www.science.org/doi/10.1126/sciadv.abq8123)

```{r}
#| echo: true
chat <- chat("openai/gpt-4.1")
type_crime <- type_object(
  crime_type = type_enum(
    c("violent", "property", "drug", "dui offense", 
      "public order", "criminal traffic", "not known/missing"),
    "If violent and another type clearly applies, choose violent,
     but only if intent to harm or injure is clearly present."
  ),
  uncertainty = type_number(
    "Your uncertainty in the classification responses and scores,
     higher scores reflect unclear or difficult to classify descriptions,
     ranging from 0.0 to 1.0."
  )
)
```

## Crimes

Data source: [Pennsylvania Courts](http://www.pacourts.us), *n* = 1,537

```{r}
#| echo: true
crimes <- read.csv("cls_offense/crimes.csv")
oai_dat <- parallel_chat_structured(
  chat,
  prompts = as.list(crimes$description),
  type = type_crime,
  include_cost = TRUE
)
mean(1 - oai_dat$uncertainty)
sum(oai_dat$cost)
```

Agreement with [ML tool](https://cjars-toc.isr.umich.edu): 81%

## Advanced workflows
::::: columns
::: {.column width="50%"}
### Development {.text-center .fragment .fade-up data-fragment-index="1"}
::: {.fragment .fade-up data-fragment-index="2"}
::: {style="background: rgba(102, 126, 234, 0.1); padding: 1.5rem; border-radius: 10px; border-left: 4px solid #667eea;"}
ðŸ¤– **LLM**: Classify

ðŸ‘¥ **Human**: Review

âš¡ **ML**: Train
:::
:::
:::
::: {.column width="50%"}
### Production {.text-center .fragment .fade-up data-fragment-index="3"}
::: {.fragment .fade-up data-fragment-index="4"}
::: {style="background: rgba(102, 126, 234, 0.1); padding: 1.5rem; border-radius: 10px; border-left: 4px solid #f093fb;"}
âš¡ **ML**: Classify

ðŸ¤– **LLM**: Classify

ðŸ‘¥ **Human**: Compare

âš¡ **ML**: Train
:::
:::
:::
:::::

## What's the catch?

::: {.incremental}
-   Frontier models are a "black box" 
    -   Billions of parameters obscure behaviors
    -   Unknown/proprietary training datasets
    -   Unknown/secretive training and fine-tuning methods
-   Local, open-source models often perform poorly
-   LLMs are non-deterministic (not always consistent)
:::

## LLM reliability

::::: columns
::: {.column width="50%"}
::: {.fragment .fade-up data-fragment-index="1"}
### First Run

```{r}
#| echo: true
chat <- chat("openai/gpt-4.1")
chat$chat("Tell a joke")
```
:::
:::

::: {.column width="50%"}
::: {.fragment .fade-up data-fragment-index="2"}
### Second Run

```{r}
#| echo: true
chat <- chat("openai/gpt-4.1")
chat$chat("Tell a joke")
```
:::
:::
:::::

::: {.fragment .fade-up data-fragment-index="3" style="text-align: center; margin-top: 30px;"}
**Same input â†’ Different outputs**

*More consistent when prompts are specific*

*Always validate and look at the responses*
:::

## Takeaways

LLMs are:

::: {.incremental}
-   Good at **extraction** and **classification**
-   Complimentary to traditional ML (not better than)
-   Best used with caution and for exploration
-   Cheap but the cost is not trivial
-   **Bonus**: To save costs, use ellmer's [`batch_chat()`](https://ellmer.tidyverse.org/reference/batch_chat.html):
    -   OpenAI
    -   Anthropic
-   
:::

## Thank you!

::::: columns
::: {.column}
### Dylan Pieper

**University of Pittsburgh**

::: {style="font-size: 0.8em;"}
ðŸ“§ djp119\@pitt.edu\
ðŸ¦‹ @dylanpieper.bsky.social\
ðŸ’» [github.com/dylanpieper](https://github.com/dylanpieper)
:::

### Questions?

*Let's discuss data!*
:::

::: {.column}
```{r}
#| fig-width: 4
#| fig-height: 4
#| fig-align: center
qrcode::qr_code("https://github.com/dylanpieper/posit-conf-2025") |> 
  plot(col = c("black", "white"))
```
:::
:::::