---
title: "From messy to meaningful data"
subtitle: "LLM-powered classification in R ðŸª„"
author: "Dylan Pieper"
institute: "University of Pittsburgh"
format: 
  revealjs:
    theme: [dark, custom.css]
    slide-number: false
    margin: 0.05
    width: 1200
    height: 900
    transition: slide
    background-transition: fade
    highlight-style: github-dark
    code-line-numbers: true
    code-overflow: wrap
    fig-cap-location: bottom
    footer: "github.com/dylanpieper/posit-25"
cache: true
---

## Magic does exist {.fade-in}

::::: columns
::: {.column width="60%"}
::: {.fragment .zoom-in style="text-align: center;"}
![](images/llm_workflow.png){fig-alt="LLM Workflow" width="440"}
:::
:::
::: {.column width="40%"}
### LLMs make unstructured data analysis accessible {.fragment .fade-in-then-semi-out}

::: {.fragment .fade-up}
One model to process thousands of texts, documents, and images
:::
:::
:::::

## What we'll cover today

::::: columns
::: {.column width="60%"}
::: {.fragment .zoom-in style="text-align: center;"}
![](https://ellmer.tidyverse.org/logo.png){fig-alt="Ellmer R package logo"}
:::
:::
::: {.column width="40%"}
### Use [`library(ellmer)`](https://ellmer.tidyverse.org/) for robust classification, focusing on: {.fragment .fade-in-then-semi-out} 

::: {.fragment .fade-up}
-   Structure
-   Prompting  
-   Accuracy
-   Confidence
-   Validation
:::
:::

:::::

## What is extraction? {auto-animate="true"}
Describe the distinct **features** of an object

::: {style="font-size: 0.8em;"}
::: columns
::: {.column width="33%"}
### Setosa
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/setosa.jpg){fig-alt="Iris setosa flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia, public domain
:::

- Smallest
- Short petals  
- Wide sepals
:::

::: {.column width="33%"}
### Virginica
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/virginica.jpg){fig-alt="Iris virginica flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia by Eric Hunt, CC-BY-SA 4.0
:::

- Medium sized
- Most variable
- Balanced proportions
:::

::: {.column width="33%"}
### Versicolor
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/versicolor.jpg){fig-alt="Iris versicolor flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia by D. Gordon E. Robertson, CC-BY-SA 3.0
:::

- Largest
- Long petals
- Narrow structure
:::
:::
:::

## What is classification? {auto-animate="true"}
Predict the distinct **category** an object belongs to

::: {style="font-size: 0.8em;"}
::: columns
::: {.column width="33%"}
### Setosa
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/setosa.jpg){fig-alt="Iris setosa flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia, public domain
:::

- <span style="color: #90EE90; font-weight: bold;">.95 setosa</span>
- .05 virginica
- .05 versicolor
:::

::: {.column width="33%"}
### Virginica
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/virginica.jpg){fig-alt="Iris virginica flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia by Eric Hunt, CC-BY-SA 4.0
:::

- .05 setosa
- <span style="color: #90EE90; font-weight: bold;">.95 virginica</span>
- .05 versicolor
:::

::: {.column width="33%"}
### Versicolor
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/versicolor.jpg){fig-alt="Iris versicolor flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia by D. Gordon E. Robertson, CC-BY-SA 3.0
:::

- .05 setosa
- .05 virginica
- <span style="color: #90EE90; font-weight: bold;">.95 versicolor</span>
:::
:::
:::

<!-- ## Traditional classification -->

<!-- ::::: columns -->
<!-- ::: {.column width="60%"} -->
<!-- ::: {.fragment .zoom-in style="text-align: center;"} -->
<!-- ![](images/ml_workflow.png){fig-alt="ML Classification Workflow" width="440"} -->
<!-- ::: -->
<!-- ::: -->
<!-- ::: {.column width="40%"} -->
<!-- ### Traditional ML requires lots of data for training {.fragment .fade-in-then-semi-out} -->

<!-- ::: {.fragment .fade-up} -->
<!-- But it encourages us to examine the **accuracy** and **uncertainty** of our predictions -->
<!-- ::: -->
<!-- ::: -->
<!-- ::::: -->

## Specify type structure

![](images/versicolor.jpg){fig-alt="Iris versicolor flower" style="height: 150px;"} Iris versicolor

```{r}
#| echo: false
library(ellmer)
library(dplyr)
library(ggplot2)
library(glue)
```

```{r}
#| echo: true
#| code-line-numbers: "1|2-6|7-10"
chat <- chat("anthropic/claude-sonnet-4-20250514")
type_flower <- type_object(
  genus    = type_string(),
  species  = type_string(),
  features = type_string("Focus on morphology"),
)
str(chat$chat_structured(
  content_image_file("images/versicolor.jpg"),
  type = type_flower
))
```

## Mimic traditional ML output

![](images/versicolor.jpg){fig-alt="Iris versicolor flower" style="height: 150px;"}  Iris versicolor

```{r}
#| echo: true
#| code-line-numbers: "1|2-7|8-10"
prob <- "Probability (0.00-1.00) Iris is {{species}}"
type_flower <- type_object(
  species         = type_enum(c("setosa", "virginica", "versicolor")),
  prob_setosa     = type_number(interpolate(prob, species = "setosa")),
  prob_virginica  = type_number(interpolate(prob, species = "virginica")),
  prob_versicolor = type_number(interpolate(prob, species = "versicolor"))
)
str(chat$clone()$chat_structured(
  content_image_file("images/versicolor.jpg"), type = type_flower
))
```

## Evaluate task limitations

![](images/setosa.jpg){fig-alt="Iris setosa flower" style="height: 150px;"}
![](images/virginica.jpg){fig-alt="Iris virginica flower" style="height: 150px;"}
![](images/versicolor.jpg){fig-alt="Iris versicolor flower" style="height: 150px;"}

```{r}
#| echo: true
#| code-line-numbers: "1-2|3-7|8"
parallel_chat_structured(
  chat = chat$clone(),
  prompts = list(
    content_image_file("images/setosa.jpg"),
    content_image_file("images/virginica.jpg"),
    content_image_file("images/versicolor.jpg")
  ),
  type = type_flower
)
```

## Adjust your expectations

![](images/setosa.jpg){fig-alt="Iris setosa flower" style="height: 150px;"}
![](images/rose.jpg){fig-alt="Rose flower" style="height: 150px;"}

```{r}
#| echo: true
#| code-line-numbers: "1-3|4-10"
type_flower <- type_object(
  genus = type_enum(c( "iris", "rose")),
)
parallel_chat_structured(
  chat = chat$clone(),
  prompts = list(
    content_image_file("images/setosa.jpg"),
    content_image_file("images/rose.jpg")
  ),
  type = type_flower
)
```

## Prompting philosophy {auto-animate="true"}

::::: columns
::: {.column width="50%"}
### Less is more {.fragment .fade-up .fade-up data-fragment-index="1"}

::: {.fragment .fade-up data-fragment-index="1"}
âœ… **Focus on**

-   Clear structure
-   Task limitations
:::

::: {.fragment .fade-up data-fragment-index="3"}
âœ… **Add context for**

-   Edge cases
-   What if multiple categories fit?
:::
:::

::: {.column width="50%"}
::: {.fragment .fade-up data-fragment-index="2"}
### Evidence {.text-center}

> "There was no need to provide those carefully crafted 20,000 tokens of context and, worse than that, doing so actually *hurt* performance."

[Simon Couch (2025)](https://www.simonpcouch.com/blog/2025-08-26-predictive/)
:::
:::
:::::

## Disease symptoms

::::: columns
::: {.column width="40%"}
::: {.fragment .fade-up style="text-align: center;"}
![](images/psoriasis.jpg){fig-alt="Psoriasis rash" style="height: 500px;"}
:::
:::

::: {.column width="60%"}
::: {.fragment .fade-up}
### Psoriasis

> "The skin on my palms and soles is thickened and has deep cracks. These cracks are painful and bleed easily."
:::
:::
:::::

## Disease symptoms

Data source: [Kaggle](https://www.kaggle.com/datasets/niyarrbarman/symptom2disease/data), public domain, *n* = 1,200

```{r}
#| echo: true
#| code-line-numbers: "1|2-7|8"
symptoms <- read.csv("cls_health/Symptom2Disease.csv")
type_health <- type_object(
  diagnosis   = type_enum(unique(symptoms$label)), # n = 24
  uncertainty = type_number("Err on the side of caution, and
                             provide a score (0.00-1.00) of
                             uncertainty in your diagnosis.")
)
unique(symptoms$label) |> head(12)
```

## Disease symptoms

```{r}
#| echo: true
#| eval: false
#| code-line-numbers: "1-2|3-5|6"
oai_dat <- parallel_chat_structured(
  chat = chat("openai/gpt-5-mini"),
  prompts = as.list(symptoms$text),
  type = type_health,
  include_cost = TRUE
)
```

```{r}
#| echo: false
oai_dat <- read.csv("cls_health/oai_dat.csv")
accuracy <- round(mean(oai_dat$diagnosis == symptoms$label) * 100, 0)
confidence <- round((1 - mean(oai_dat$uncertainty)) * 100, 0)
cost <- round(sum(oai_dat$cost), 2)
```

::: {.fragment .fade-up}
```{r}
#| echo: true
#| eval: false
accuracy <- mean(oai_dat$diagnosis == symptoms$label)
confidence <- 1 - mean(oai_dat$uncertainty)
cost <- sum(oai_dat$cost)
```
:::

::: {.incremental}
-   **Accuracy**: `r accuracy`% (vs. 93% in tidymodels) ðŸ«£
-   **Confidence**: `r confidence`%
-   **Cost**: $`r cost`
:::

## Disease symptoms

```{r}
#| echo: false
accuracy_by_diagnosis <- tibble::tibble(
  true_label = symptoms$label,
  predicted = oai_dat$diagnosis
) |>
  dplyr::mutate(correct = true_label == predicted) |>
  dplyr::group_by(true_label) |>
  dplyr::summarise(
    n_cases = dplyr::n(),
    n_correct = sum(correct),
    accuracy = n_correct / n_cases,
    .groups = "drop"
  ) |>
  dplyr::arrange(accuracy) |>
  dplyr::mutate(
    diagnosis = stringr::str_to_title(stringr::str_replace_all(true_label, "_", " ")),
    diagnosis = forcats::fct_reorder(diagnosis, accuracy)
  )

accuracy_by_diagnosis |>
  ggplot2::ggplot(ggplot2::aes(accuracy, diagnosis, fill = accuracy)) +
  ggplot2::geom_col(alpha = 0.9, width = 0.7) +
  ggplot2::geom_text(
    ggplot2::aes(label = scales::percent(accuracy, accuracy = 1)),
    hjust = -0.1, 
    color = "#e5e5e5", 
    size = 3.5
  ) +
  ggplot2::scale_fill_gradient(
    low = "#f87171", 
    high = "#4ade80",
    guide = "none"
  ) +
  ggplot2::scale_x_continuous(
    labels = scales::percent_format(),
    expand = ggplot2::expansion(mult = c(0, 0.15))
  ) +
  ggplot2::labs(
    title = "LLM classification accuracy varies by diagnosis",
    x = "Classification accuracy",
    y = NULL
  ) +
  ggplot2::theme_minimal() +
  ggplot2::theme(
    plot.background = ggplot2::element_rect(fill = "#000", color = NA),
    panel.background = ggplot2::element_rect(fill = "#000", color = NA),
    panel.grid.major.y = ggplot2::element_blank(),
    panel.grid.minor = ggplot2::element_blank(),
    panel.grid.major.x = ggplot2::element_line(color = "#404040", linewidth = 0.3),
    text = ggplot2::element_text(color = "#e5e5e5", family = "Arial"),
    plot.title = ggplot2::element_text(size = 16, face = "bold", margin = ggplot2::margin(b = 5)),
    plot.subtitle = ggplot2::element_text(size = 12, color = "#a5a5a5"),
    axis.text = ggplot2::element_text(color = "#e5e5e5", size = 11),
    axis.title = ggplot2::element_text(color = "#e5e5e5", size = 12)
  )
```

## Disease symptoms

```{r}
#| echo: false
diag_errors <- tibble::tibble(
  true_label = symptoms$label,
  predicted = oai_dat$diagnosis,
  certainty = 1 - oai_dat$uncertainty
) |>
  mutate(
    error = true_label != predicted,
    error_rate = as.numeric(error)
  )

correlation <- cor(diag_errors$certainty, diag_errors$error_rate, method = "spearman")

certainty_plot <- diag_errors |>
  mutate(
    certainty_bin = case_when(
      certainty >= 0.95 ~ "Very High\n(â‰¥ 0.95)",
      certainty >= 0.75 ~ "High\n(0.75-0.95)",
      certainty >= 0.50 ~ "Medium\n(0.50-0.75)",
      TRUE ~ "Low\n(< 0.50)"
    ) |>
      factor(levels = c("Low\n(< 0.50)", "Medium\n(0.50-0.75)", "High\n(0.75-0.95)", "Very High\n(â‰¥ 0.95)"))
  ) |>
  count(certainty_bin, error) |>
  group_by(certainty_bin) |>
  mutate(
    total = sum(n),
    prop = n / total,
    error_label = ifelse(error, "Error", "Correct")
  )

certainty_plot |>
  ggplot2::ggplot(ggplot2::aes(certainty_bin, prop, fill = error_label)) +
  ggplot2::geom_col(position = "stack", width = 0.7, alpha = 0.9) +
  ggplot2::scale_fill_manual(
    values = c("Correct" = "#4ade80", "Error" = "#f87171"),
    name = ""
  ) +
  ggplot2::scale_y_continuous(
    labels = scales::percent_format(),
    expand = c(0, 0)
  ) +
  ggplot2::labs(
    title = "LLM certainty predicts classification accuracy",
    subtitle = glue::glue("Higher certainty â†’ lower error rates (r = {round(correlation, 3)})"),
    x = "LLM certainty",
    y = "Proportion of cases"
  ) +
  ggplot2::theme_minimal() +
  ggplot2::theme(
    plot.background = ggplot2::element_rect(fill = "#000", color = NA),
    panel.background = ggplot2::element_rect(fill = "#000", color = NA),
    panel.grid = ggplot2::element_line(color = "#404040", linewidth = 0.3),
    panel.grid.minor = ggplot2::element_blank(),
    text = ggplot2::element_text(color = "#e5e5e5", family = "Arial"),
    plot.title = ggplot2::element_text(size = 16, face = "bold", margin = ggplot2::margin(b = 5)),
    plot.subtitle = ggplot2::element_text(size = 12, color = "#a5a5a5"),
    axis.text = ggplot2::element_text(color = "#e5e5e5", size = 11),
    axis.title = ggplot2::element_text(color = "#e5e5e5", size = 12),
    legend.text = ggplot2::element_text(size = 11),
    legend.position = "top"
  )
```

## Crimes

::::: columns
::: {.column width="40%"}
::: {.fragment .fade-up style="text-align: center;"}
![](images/psp.jpg){fig-alt="Pennsylvania State Police"}
Source: [PA.gov](https://www.pa.gov/agencies/dgs/programs-and-services/capitol-police)
:::
:::

::: {.column width="60%"}
::: {.fragment .fade-up}
### Police reports
Descriptions of crimes

> "Criminal Conspiracy Engaging Harassment - Comm. Lewd, Threatening, Etc. Language"
:::
:::
:::::

## Crimes

Schema source: [Uniform Crime Classification Standard](https://www.science.org/doi/10.1126/sciadv.abq8123)

```{r}
#| echo: true
type_crime <- type_object(
  crime_type = type_enum(
    c("violent", "property", "drug", "dui offense", 
      "public order", "criminal traffic", "not known/missing"),
    "If violent and another type clearly applies, choose violent,
     but only if intent to harm or injure is clearly present.
     Threats, harassment, stalking, and similar are all violent."
  ),
  uncertainty = type_number(
    "Your uncertainty in the classification responses and scores,
     higher scores reflect unclear or difficult to classify descriptions,
     ranging from 0.0 to 1.0."
  )
)
```

## Crimes

Data source: [Pennsylvania Courts](http://www.pacourts.us), *n* = 1,537

```{r}
#| echo: true
#| eval: false
#| code-line-numbers: "1|2-7"
crimes <- read.csv("cls_offense/crimes.csv")
oai_dat <- parallel_chat_structured(
  chat = chat("openai/gpt-5-mini"),
  prompts = as.list(crimes$description),
  type = type_crime,
  include_cost = TRUE
)
```

```{r}
#| echo: false
oai_dat <- read.csv("cls_offense/oai_dat.csv")
certainty <- round((1 - mean(oai_dat$uncertainty)) * 100)
cost <- round(sum(oai_dat$cost), 2)
```

:::{.incremental}
-   Agreement with [ML tool](https://cjars-toc.isr.umich.edu): 81% ðŸŽ¯
-   Certainty: `r certainty`%
-   Cost: $`r cost`
:::

## Crimes

::: {style="font-size: 0.7em;"}
```{r}
#| echo: false
toc <- openxlsx::readWorkbook("cls_offense/cjars_toc.xlsx", sheet = 2)
toc_uccs <- openxlsx::readWorkbook("cls_offense/cjars_toc.xlsx", sheet = 3)

oai_dat <- utils::read.csv("cls_offense/oai_dat.csv") |>
  dplyr::relocate(description)

toc_processed <- toc |>
  dplyr::mutate(dplyr::across(where(is.numeric), ~ round(.x, 3))) |>
  dplyr::left_join(toc_uccs, by = "uccs_code") |>
  dplyr::mutate(
    description = stringr::str_squish(description),
    charge_desc = tolower(charge_desc),
    offense_type_desc = tolower(offense_type_desc)
  ) |>
  dplyr::select(description, toc_offense_category = charge_desc, 
                toc_offense_type = offense_type_desc, toc_confidence = probability)

oai_processed <- oai_dat |>
  dplyr::mutate(description = stringr::str_squish(description),
                llm_certainty = 1 - uncertainty_score) |>
  dplyr::select(description,
                openai_offense_category = offense_category,
                openai_offense_type = offense_type,
                llm_certainty)

combined_data <- toc_processed |>
  dplyr::left_join(oai_processed, by = "description") |>
  dplyr::mutate(
    toc_certainty = toc_confidence,
    classification_agreement = toc_offense_type == openai_offense_type,
    is_animal_cruelty = stringr::str_detect(tolower(description), "cruelty")
  ) |>
  dplyr::filter(!is.na(toc_certainty), !is.na(llm_certainty))

certainty_cor <- cor(combined_data$toc_certainty, 
                      combined_data$llm_certainty, 
                      method = "spearman")
classification_agreement_rate <- mean(combined_data$classification_agreement, na.rm = TRUE)

animal_cases <- combined_data |>
  dplyr::filter(is_animal_cruelty) |>
  dplyr::mutate(
    toc_says_violent = toc_offense_type == "violent",
    llm_says_violent = openai_offense_type == "violent",
    systematic_error = !toc_says_violent & llm_says_violent
  )

animal_cases |>
  dplyr::filter(systematic_error) |>
  dplyr::select(description, toc_offense_type, toc_confidence,
                openai_offense_type, llm_certainty) |>
  head(2) |>
  knitr::kable(
    col.names = c("Description", "ML Tool", "ML Cert.", "LLM", "LLM Cert."),
    caption = "ML tool misclassifies animal cruelty as non-violent"
  )
```
:::

::: {.fragment .zoom-in style="text-align: center;"}
High certainty â‰  correct classification
:::

## Crimes

```{r}
#| echo: false
combined_data |>
  ggplot2::ggplot(ggplot2::aes(toc_certainty, llm_certainty, color = classification_agreement)) +
  ggplot2::geom_point(alpha = 0.6, size = 1.2) +
  ggplot2::geom_smooth(method = "lm", se = FALSE, color = "#f87171", linewidth = 1) +
  ggplot2::scale_color_manual(
    values = c("TRUE" = "#4ade80", "FALSE" = "#f87171"),
    labels = c("TRUE" = "Agreement", "FALSE" = "Disagreement"),
    name = "Classification"
  ) +
  ggplot2::labs(
    title = "Cross-model certainty validation",
    subtitle = glue::glue("81% classification agreement, r = {round(certainty_cor, 3)} certainty correlation"),
    x = "ML tool certainty",
    y = "LLM certainty"
  ) +
  ggplot2::theme_minimal() +
  ggplot2::theme(
    plot.background = ggplot2::element_rect(fill = "#000", color = NA),
    panel.background = ggplot2::element_rect(fill = "#000", color = NA),
    panel.grid = ggplot2::element_line(color = "#404040", linewidth = 0.3),
    panel.grid.minor = ggplot2::element_blank(),
    text = ggplot2::element_text(color = "#e5e5e5", family = "Arial"),
    plot.title = ggplot2::element_text(size = 16, face = "bold"),
    plot.subtitle = ggplot2::element_text(size = 12, color = "#a5a5a5"),
    axis.text = ggplot2::element_text(color = "#e5e5e5", size = 11),
    axis.title = ggplot2::element_text(color = "#e5e5e5", size = 12),
    legend.text = ggplot2::element_text(color = "#e5e5e5", size = 11),
    legend.title = ggplot2::element_text(color = "#e5e5e5", size = 12),
    legend.position = "top"
  )
```

## Crimes
::: {style="font-size: 0.8em;"}
```{r}
#| echo: false
# Find one case where ML confident, LLM uncertain
ml_confident <- combined_data |>
  dplyr::filter(
    toc_offense_type != openai_offense_type & 
    toc_certainty >= 0.9 & llm_certainty <= 0.5
  ) |>
  dplyr::slice(2)

# Find one case where LLM confident, ML uncertain  
llm_confident <- combined_data |>
  dplyr::filter(
    toc_offense_type != openai_offense_type & 
    llm_certainty >= 0.9 & toc_certainty <= 0.5
  ) |>
  dplyr::slice_head(n = 1)

# Combine cases
both_cases <- dplyr::bind_rows(ml_confident, llm_confident) |>
  dplyr::mutate(
    description_short = ifelse(nchar(description) > 40, 
                              paste0(substr(description, 1, 40), "..."), 
                              description),
    toc_certainty = round(toc_certainty, 2)
  ) |>
  dplyr::select(description_short, toc_offense_type, toc_certainty,
                openai_offense_type, llm_certainty)

both_cases |>
  knitr::kable(
    col.names = c("Description", "ML Tool", "ML Cert.", "LLM", "LLM Cert."),
    digits = 3
  )
```
:::

## Advanced workflows
::::: columns
::: {.column width="50%"}
### Development {.text-center .fragment .fade-up data-fragment-index="1"}
::: {.fragment .fade-up data-fragment-index="2"}
::: {style="background: rgba(102, 126, 234, 0.1); padding: 1.5rem; border-radius: 10px; border-left: 4px solid #667eea;"}
ðŸ¤– **LLM**: Classify

ðŸ‘¥ **Human**: Review

âš¡ **ML**: Train
:::
:::
:::
::: {.column width="50%"}
### Production {.text-center .fragment .fade-up data-fragment-index="3"}
::: {.fragment .fade-up data-fragment-index="4"}
::: {style="background: rgba(102, 126, 234, 0.1); padding: 1.5rem; border-radius: 10px; border-left: 4px solid #f093fb;"}
âš¡ **ML**: Classify

ðŸ¤– **LLM**: Classify

ðŸ‘¥ **Human**: Compare

âš¡ **ML**: Train
:::
:::
:::
:::::

## What's the catch?

::: {.incremental}
-   Frontier models are a **black box**
    -   Billions of parameters obscure behaviors
    -   Unknown/proprietary training datasets
    -   Unknown/secretive training and fine-tuning methods
-   Local, open-source models often perform poorly
-   LLMs are **non-deterministic** (not always consistent)
:::

## LLM reliability

::::: columns
::: {.column width="50%"}
::: {.fragment .fade-up data-fragment-index="1"}
### First Run

```{r}
#| echo: true
chat <- chat("openai/gpt-5-mini")
chat$chat("Tell a joke")
```
:::
:::

::: {.column width="50%"}
::: {.fragment .fade-up data-fragment-index="2"}
### Second Run

```{r}
#| echo: true
chat <- chat("openai/gpt-5-mini")
chat$chat("Tell a joke")
```
:::
:::
:::::

::: {.fragment .fade-up data-fragment-index="3" style="text-align: center; margin-top: 30px;"}
**Same input â†’ Different outputs**

*Always validate and look at the responses*
:::

## Takeaways

::: {.incremental}
-   LLMs are accessible tools for **unstructured data analysis**
-   Use minimal prompting that focuses on **data structure** and **task boundaries** or **limitations**
-   Use **uncertainty scores** and **human review** to evaluate LLM output
-   Use LLMs to **develop** and **improve** existing ML tools
:::

## Thank you!

::::: columns
::: {.column}
### Dylan Pieper

**University of Pittsburgh**

::: {style="font-size: 0.8em;"}
ðŸ“§ djp119\@pitt.edu\
ðŸ¦‹ @dylanpieper.bsky.social\
ðŸ’» [github.com/dylanpieper](https://github.com/dylanpieper)
:::

### Questions?

*Let's discuss LLMs!*
:::

::: {.column}
```{r}
#| fig-width: 4
#| fig-height: 4
#| fig-align: center
qrcode::qr_code("https://github.com/dylanpieper/posit-25") |> 
  plot(col = c("black", "white"))
```
:::
:::::