---
title: "Extract and classify data with LLM APIs"
subtitle: "A practical guide in R"
author: "Dylan Pieper<br/>Data & Social Scientist"
institute: "posit::conf(2025)<br/>University of Pittsburgh"
format: 
  revealjs:
    theme: [dark, custom.css]
    slide-number: true
    margin: 0.05
    width: 1200
    height: 900
    transition: slide
    background-transition: fade
    highlight-style: github-dark
    code-line-numbers: true
    code-overflow: wrap
    fig-cap-location: bottom
cache: true
---

## Dreams do come true {.fade-in}

::::: columns
::: {.column width="60%"}
::: {.fragment .zoom-in style="text-align: center;"}
![](images/llm_workflow.png){fig-alt="LLM Workflow" width="440"}
:::
:::
::: {.column width="40%"}
### LLMs make unstructured data analysis accessible {.fragment .fade-in-then-semi-out}

::: {.fragment .fade-up}
One model to process thousands of texts, documents, and images
:::
:::
:::::

## What is extraction? {auto-animate="true"}
Describe the distinct **features** of an object

::: {style="font-size: 0.8em;"}
::: columns
::: {.column width="33%"}
### Setosa
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/setosa.jpg){fig-alt="Iris setosa flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia, public domain
:::

- Smallest
- Short petals  
- Wide sepals
:::

::: {.column width="33%"}
### Virginica
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/virginica.jpg){fig-alt="Iris virginica flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia by Eric Hunt, CC-BY-SA 4.0
:::

- Medium sized
- Most variable
- Balanced proportions
:::

::: {.column width="33%"}
### Versicolor
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/versicolor.jpg){fig-alt="Iris versicolor flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia by D. Gordon E. Robertson, CC-BY-SA 3.0
:::

- Largest
- Long petals
- Narrow structure
:::
:::
:::

## What is classification? {auto-animate="true"}
Predict the distinct **category** an object belongs to

::: {style="font-size: 0.8em;"}
::: columns
::: {.column width="33%"}
### Setosa
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/setosa.jpg){fig-alt="Iris setosa flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia, public domain
:::

- <span style="color: #90EE90; font-weight: bold;">.95 setosa</span>
- .05 virginica
- .05 versicolor
:::

::: {.column width="33%"}
### Virginica
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/virginica.jpg){fig-alt="Iris virginica flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia by Eric Hunt, CC-BY-SA 4.0
:::

- .05 setosa
- <span style="color: #90EE90; font-weight: bold;">.95 virginica</span>
- .05 versicolor
:::

::: {.column width="33%"}
### Versicolor
::: {style="font-size: 0.5em; height: 320px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 20px;" data-auto-animate="false"}
![](images/versicolor.jpg){fig-alt="Iris versicolor flower" style="height: 260px; width: 100%; object-fit: cover;"}
Wikipedia by D. Gordon E. Robertson, CC-BY-SA 3.0
:::

- .05 setosa
- .05 virginica
- <span style="color: #90EE90; font-weight: bold;">.95 versicolor</span>
:::
:::
:::

## Traditional classification

::::: columns
::: {.column width="60%"}
::: {.fragment .zoom-in style="text-align: center;"}
![](images/ml_workflow.png){fig-alt="ML Classification Workflow" width="440"}
:::
:::
::: {.column width="40%"}
### Traditional ML requires lots of data for training and testing {.fragment .fade-in-then-semi-out}

::: {.fragment .fade-up}
But it encourages us to examine the accuracy and uncertainty of our predictions
:::
:::
:::::

## What we'll cover today

::::: columns
::: {.column width="60%"}
::: {.fragment .zoom-in style="text-align: center;"}
![](https://ellmer.tidyverse.org/logo.png){fig-alt="Ellmer R package logo"}
:::
:::
::: {.column width="40%"}
### Use [`library(ellmer)`](https://ellmer.tidyverse.org/) to extract and classify data {.fragment .fade-in-then-semi-out}

::: {.fragment .fade-in-then-semi-out}
With robustness and care for delicate use cases 
:::

::: {.fragment .fade-up}
-   **Iris flowers** → prompting  
-   **Health symptoms** → uncertainty
-   **Crimes** → validation
:::
:::

:::::

## Getting started with ellmer

![](images/versicolor.jpg){fig-alt="Iris versicolor flower" style="height: 150px;"} Iris versicolor

```{r}
#| echo: false
library(ellmer)
library(dplyr)
library(ggplot2)
library(glue)
```

```{r}
#| echo: true
chat <- chat("anthropic/claude-sonnet-4-20250514")
type_flower <- type_object(
  genus    = type_string(),
  species  = type_string(),
  features = type_string("Focus on morphology"),
)
str(chat$chat_structured(
  content_image_file("images/versicolor.jpg"), # or content_pdf_file(), or text
  type = type_flower
))
```

## Getting better with ellmer

![](images/versicolor.jpg){fig-alt="Iris versicolor flower" style="height: 150px;"}  Iris versicolor

```{r}
#| echo: true
prob <- "Probability (0.00-1.00) Iris is {{species}}"
type_flower <- type_object(
  species         = type_enum(c("setosa", "virginica", "versicolor")),
  prob_setosa     = type_number(interpolate(prob, species = "setosa")),
  prob_virginica  = type_number(interpolate(prob, species = "virginica")),
  prob_versicolor = type_number(interpolate(prob, species = "versicolor"))
)
str(chat$clone()$chat_structured(
  content_image_file("images/versicolor.jpg"), type = type_flower
))
```

## Getting upset with ellmer

![](images/setosa.jpg){fig-alt="Iris setosa flower" style="height: 150px;"}
![](images/virginica.jpg){fig-alt="Iris virginica flower" style="height: 150px;"}
![](images/versicolor.jpg){fig-alt="Iris versicolor flower" style="height: 150px;"}

```{r}
#| echo: true
parallel_chat_structured(
  chat = chat$clone(),
  prompts = list(
    content_image_file("images/setosa.jpg"),
    content_image_file("images/virginica.jpg"),
    content_image_file("images/versicolor.jpg")
  ),
  type = type_flower
)
```

## Making peace with ellmer

![](images/setosa.jpg){fig-alt="Iris setosa flower" style="height: 150px;"}
![](images/rose.jpg){fig-alt="Rose flower" style="height: 150px;"}

```{r}
#| echo: true
type_flower <- type_object(
  genus = type_enum(c( "iris", "rose")),
)
parallel_chat_structured(
  chat = chat$clone(),
  prompts = list(
    content_image_file("images/setosa.jpg"),
    content_image_file("images/rose.jpg")
  ),
  type = type_flower
)
```

## Prompting philosophy {auto-animate="true"}

::::: columns
::: {.column width="50%"}
### Less is more {.fragment .fade-up}

::: {.fragment .fade-up}
✅ **Focus on**

-   Clear structure
-   Task limitations
:::

::: {.fragment .fade-up}
✅ **Handle edge cases**

-   What if multiple categories fit?
-   When to express uncertainty?
:::
:::

::: {.column width="50%"}
::: {.fragment .fade-up}
### Evidence {.text-center}

> "There was no need to provide those carefully crafted 20,000 tokens of context and, worse than that, doing so actually *hurt* performance."

[Simon Couch (2025)](https://www.simonpcouch.com/blog/2025-08-26-predictive/)
:::
:::
:::::

## Health symptoms

::::: columns
::: {.column width="40%"}
::: {.fragment .fade-up style="text-align: center;"}
![](images/psoriasis.jpg){fig-alt="Psoriasis rash" style="height: 500px;"}
:::
:::

::: {.column width="60%"}
::: {.fragment .fade-up}
### Psoriasis

> "The skin on my palms and soles is thickened and has deep cracks. These cracks are painful and bleed easily."
:::
:::
:::::

## Health symptoms

Data source: [Kaggle](https://www.kaggle.com/datasets/niyarrbarman/symptom2disease/data), public domain, *n* = 1,200

```{r}
#| echo: true
symptoms <- read.csv("cls_health/Symptom2Disease.csv")
chat <- chat("openai/gpt-4.1")
type_health <- type_object(
  diagnosis   = type_enum(unique(symptoms$label)), # n = 24
  uncertainty = type_number("Err on the side of caution, and
                             provide a score (0.00-1.00) of
                             uncertainty in your diagnosis.")
)
unique(symptoms$label) |> head(12)
```

## Health symptoms

```{r}
#| echo: true
oai_dat <- parallel_chat_structured(
  chat,
  prompts = as.list(symptoms$text),
  type = type_health,
  include_cost = TRUE
)
mean(oai_dat$diagnosis == symptoms$label)
mean(oai_dat$uncertainty)
sum(oai_dat$cost)
```

## Health symptoms

```{r}
#| echo: false
accuracy_by_diagnosis <- tibble::tibble(
  true_label = symptoms$label,
  predicted = oai_dat$diagnosis
) |>
  dplyr::mutate(correct = true_label == predicted) |>
  dplyr::group_by(true_label) |>
  dplyr::summarise(
    n_cases = dplyr::n(),
    n_correct = sum(correct),
    accuracy = n_correct / n_cases,
    .groups = "drop"
  ) |>
  dplyr::arrange(accuracy) |>
  dplyr::mutate(
    diagnosis = stringr::str_to_title(stringr::str_replace_all(true_label, "_", " ")),
    diagnosis = forcats::fct_reorder(diagnosis, accuracy)
  )

accuracy_by_diagnosis |>
  ggplot2::ggplot(ggplot2::aes(accuracy, diagnosis, fill = accuracy)) +
  ggplot2::geom_col(alpha = 0.9, width = 0.7) +
  ggplot2::geom_text(
    ggplot2::aes(label = scales::percent(accuracy, accuracy = 1)),
    hjust = -0.1, 
    color = "#e5e5e5", 
    size = 3.5
  ) +
  ggplot2::scale_fill_gradient(
    low = "#f87171", 
    high = "#4ade80",
    guide = "none"
  ) +
  ggplot2::scale_x_continuous(
    labels = scales::percent_format(),
    expand = ggplot2::expansion(mult = c(0, 0.15))
  ) +
  ggplot2::labs(
    title = "LLM classification accuracy varies by diagnosis",
    x = "Classification accuracy",
    y = NULL
  ) +
  ggplot2::theme_minimal() +
  ggplot2::theme(
    plot.background = ggplot2::element_rect(fill = "#000", color = NA),
    panel.background = ggplot2::element_rect(fill = "#000", color = NA),
    panel.grid.major.y = ggplot2::element_blank(),
    panel.grid.minor = ggplot2::element_blank(),
    panel.grid.major.x = ggplot2::element_line(color = "#404040", linewidth = 0.3),
    text = ggplot2::element_text(color = "#e5e5e5", family = "Arial"),
    plot.title = ggplot2::element_text(size = 16, face = "bold", margin = ggplot2::margin(b = 5)),
    plot.subtitle = ggplot2::element_text(size = 12, color = "#a5a5a5"),
    axis.text = ggplot2::element_text(color = "#e5e5e5", size = 11),
    axis.title = ggplot2::element_text(color = "#e5e5e5", size = 12)
  )
```

## Health symptoms

```{r}
#| echo: false
diag_errors <- tibble::tibble(
  true_label = symptoms$label,
  predicted = oai_dat$diagnosis,
  uncertainty = oai_dat$uncertainty
) |>
  mutate(
    error = true_label != predicted,
    error_rate = as.numeric(error)
  )

correlation <- cor(diag_errors$uncertainty, diag_errors$error_rate, method = "spearman")

uncertainty_plot <- diag_errors |>
  mutate(
    uncertainty_bin = case_when(
      uncertainty <= 0.05 ~ "None\n(< 0.05)",
      uncertainty < 0.25 ~ "Low\n(0.05-0.25)",
      uncertainty < 0.50 ~ "Medium\n(0.25-0.50)",
      TRUE ~ "High\n(≥ 0.50)"
    ) |>
      factor(levels = c("None\n(< 0.05)", "Low\n(0.05-0.25)", "Medium\n(0.25-0.50)", "High\n(≥ 0.50)"))
  ) |>
  count(uncertainty_bin, error) |>
  group_by(uncertainty_bin) |>
  mutate(
    total = sum(n),
    prop = n / total,
    error_label = ifelse(error, "Error", "Correct")
  )

uncertainty_plot |>
  ggplot2::ggplot(ggplot2::aes(uncertainty_bin, prop, fill = error_label)) +
  ggplot2::geom_col(position = "stack", width = 0.7, alpha = 0.9) +
  ggplot2::scale_fill_manual(
    values = c("Correct" = "#4ade80", "Error" = "#f87171"),
    name = ""
  ) +
  ggplot2::scale_y_continuous(
    labels = scales::percent_format(),
    expand = c(0, 0)
  ) +
  ggplot2::labs(
    title = "LLM uncertainty predicts classification errors",
    subtitle = glue::glue("Higher uncertainty → higher error rates (r = {round(correlation, 3)})"),
    x = "LLM uncertainty",
    y = "Proportion of cases"
  ) +
  ggplot2::theme_minimal() +
  ggplot2::theme(
    plot.background = ggplot2::element_rect(fill = "#000", color = NA),
    panel.background = ggplot2::element_rect(fill = "#000", color = NA),
    panel.grid = ggplot2::element_line(color = "#404040", linewidth = 0.3),
    panel.grid.minor = ggplot2::element_blank(),
    text = ggplot2::element_text(color = "#e5e5e5", family = "Arial"),
    plot.title = ggplot2::element_text(size = 16, face = "bold", margin = ggplot2::margin(b = 5)),
    plot.subtitle = ggplot2::element_text(size = 12, color = "#a5a5a5"),
    axis.text = ggplot2::element_text(color = "#e5e5e5", size = 11),
    axis.title = ggplot2::element_text(color = "#e5e5e5", size = 12),
    legend.text = ggplot2::element_text(size = 11),
    legend.position = "top"
  )
```

## Crimes

::::: columns
::: {.column width="40%"}
::: {.fragment .fade-up style="text-align: center;"}
![](images/psp.jpg){fig-alt="Pennsylvania State Police"}
Source: [PA.gov](https://www.pa.gov/agencies/dgs/programs-and-services/capitol-police)
:::
:::

::: {.column width="60%"}
::: {.fragment .fade-up}
### Police reports
Descriptions of crimes

> "Criminal Conspiracy Engaging Harassment - Comm. Lewd, Threatening, Etc. Language"
:::
:::
:::::

## Crimes

Schema source: [Uniform Crime Classification Standard](https://www.science.org/doi/10.1126/sciadv.abq8123)

```{r}
#| echo: true
chat <- chat("openai/gpt-4.1")
type_crime <- type_object(
  crime_type = type_enum(
    c("violent", "property", "drug", "dui offense", 
      "public order", "criminal traffic", "not known/missing"),
    "If violent and another type clearly applies, choose violent,
     but only if intent to harm or injure is clearly present.
     Threats, harassment, stalking, and similar are all violent."
  ),
  uncertainty = type_number(
    "Your uncertainty in the classification responses and scores,
     higher scores reflect unclear or difficult to classify descriptions,
     ranging from 0.0 to 1.0."
  )
)
```

## Crimes

Data source: [Pennsylvania Courts](http://www.pacourts.us), *n* = 1,537

```{r}
#| echo: true
crimes <- read.csv("cls_offense/crimes.csv")
oai_dat <- parallel_chat_structured( # use batch_chat() to save 50%
  chat,
  prompts = as.list(crimes$description),
  type = type_crime,
  include_cost = TRUE
)
mean(oai_dat$uncertainty)
sum(oai_dat$cost)
```

Agreement with [ML tool](https://cjars-toc.isr.umich.edu): 82%

## Crimes

::: {style="font-size: 0.7em;"}
```{r}
#| echo: false
toc <- openxlsx::readWorkbook("cls_offense/cjars_toc.xlsx", sheet = 2)
toc_uccs <- openxlsx::readWorkbook("cls_offense/cjars_toc.xlsx", sheet = 3)

oai_dat <- utils::read.csv("cls_offense/oai_dat.csv") |>
  dplyr::select(-harm_score, -action_type) |>
  dplyr::relocate(description)

toc_processed <- toc |>
  dplyr::mutate(dplyr::across(where(is.numeric), ~ round(.x, 3))) |>
  dplyr::left_join(toc_uccs, by = "uccs_code") |>
  dplyr::mutate(
    description = stringr::str_squish(description),
    charge_desc = tolower(charge_desc),
    offense_type_desc = tolower(offense_type_desc)
  ) |>
  dplyr::select(description, toc_offense_category = charge_desc, 
                toc_offense_type = offense_type_desc, toc_confidence = probability)

oai_processed <- oai_dat |>
  dplyr::mutate(description = stringr::str_squish(description)) |>
  dplyr::select(description,
                openai_offense_category = offense_category,
                openai_offense_type = offense_type, 
                llm_uncertainty = uncertainty_score)

combined_data <- toc_processed |>
  dplyr::left_join(oai_processed, by = "description") |>
  dplyr::mutate(
    toc_uncertainty = 1 - toc_confidence,
    classification_agreement = toc_offense_type == openai_offense_type,
    is_animal_cruelty = stringr::str_detect(tolower(description), "cruelty")
  ) |>
  dplyr::filter(!is.na(toc_uncertainty), !is.na(llm_uncertainty))

uncertainty_cor <- cor(combined_data$toc_uncertainty, 
                       combined_data$llm_uncertainty, 
                       method = "spearman")
classification_agreement_rate <- mean(combined_data$classification_agreement, na.rm = TRUE)

animal_cases <- combined_data |>
  dplyr::filter(is_animal_cruelty) |>
  dplyr::mutate(
    toc_says_violent = toc_offense_type == "violent",
    llm_says_violent = openai_offense_type == "violent",
    systematic_error = !toc_says_violent & llm_says_violent
  )

animal_cases |>
  dplyr::filter(systematic_error) |>
  dplyr::select(description, toc_offense_type, openai_offense_type, 
                toc_confidence, llm_uncertainty) |>
  head(2) |>
  knitr::kable(
    col.names = c("Description", "ML Tool", "LLM", "ML Confidence", "LLM Uncertainty"),
    caption = "ML tool misclassifies animal cruelty as non-violent"
  )
```
:::

::: {.fragment .zoom-in style="text-align: center;"}
High confidence ≠ correct classification
:::

## Crimes

```{r}
#| echo: false
combined_data |>
  ggplot2::ggplot(ggplot2::aes(toc_uncertainty, llm_uncertainty)) +
  ggplot2::geom_point(alpha = 0.6, color = "#4ade80") +
  ggplot2::geom_smooth(method = "lm", se = FALSE, color = "#f87171") +
  ggplot2::labs(
    title = "Cross-model uncertainty validation",
    subtitle = glue::glue("82% classification agreement, r = {round(uncertainty_cor, 3)} uncertainty correlation"),
    x = "ML tool uncertainty (1 - probability)",
    y = "LLM uncertainty"
  ) +
  ggplot2::theme_minimal() +
  ggplot2::theme(
    plot.background = ggplot2::element_rect(fill = "#000", color = NA),
    panel.background = ggplot2::element_rect(fill = "#000", color = NA),
    panel.grid = ggplot2::element_line(color = "#404040", linewidth = 0.3),
    panel.grid.minor = ggplot2::element_blank(),
    text = ggplot2::element_text(color = "#e5e5e5", family = "Arial"),
    plot.title = ggplot2::element_text(size = 16, face = "bold"),
    plot.subtitle = ggplot2::element_text(size = 12, color = "#a5a5a5"),
    axis.text = ggplot2::element_text(color = "#e5e5e5", size = 11),
    axis.title = ggplot2::element_text(color = "#e5e5e5", size = 12)
  )
```

## Advanced workflows
::::: columns
::: {.column width="50%"}
### Development {.text-center .fragment .fade-up data-fragment-index="1"}
::: {.fragment .fade-up data-fragment-index="2"}
::: {style="background: rgba(102, 126, 234, 0.1); padding: 1.5rem; border-radius: 10px; border-left: 4px solid #667eea;"}
🤖 **LLM**: Classify

👥 **Human**: Review

⚡ **ML**: Train
:::
:::
:::
::: {.column width="50%"}
### Production {.text-center .fragment .fade-up data-fragment-index="3"}
::: {.fragment .fade-up data-fragment-index="4"}
::: {style="background: rgba(102, 126, 234, 0.1); padding: 1.5rem; border-radius: 10px; border-left: 4px solid #f093fb;"}
⚡ **ML**: Classify

🤖 **LLM**: Classify

👥 **Human**: Compare

⚡ **ML**: Train
:::
:::
:::
:::::

## What's the catch?

::: {.incremental}
-   Frontier models are a **black box**
    -   Billions of parameters obscure behaviors
    -   Unknown/proprietary training datasets
    -   Unknown/secretive training and fine-tuning methods
-   Local, open-source models often perform poorly
-   LLMs are **non-deterministic** (not always consistent)
:::

## LLM reliability

::::: columns
::: {.column width="50%"}
::: {.fragment .fade-up data-fragment-index="1"}
### First Run

```{r}
#| echo: true
chat <- chat("openai/gpt-4.1")
chat$chat("Tell a joke")
```
:::
:::

::: {.column width="50%"}
::: {.fragment .fade-up data-fragment-index="2"}
### Second Run

```{r}
#| echo: true
chat <- chat("openai/gpt-4.1")
chat$chat("Tell a joke")
```
:::
:::
:::::

::: {.fragment .fade-up data-fragment-index="3" style="text-align: center; margin-top: 30px;"}
**Same input → Different outputs**

*More consistent when prompts are specific*

*Always validate and look at the responses*
:::

## Takeaways

::: {.incremental}
-   LLMs are accessible tools for **extraction** and **classification**, but be careful
-   Use minimal prompting that focuses on **structure** and **task limitations**
-   Use **uncertainty** scores to guide human review
-   Use LLMs to **develop** and **validate** existing tools
:::

## Thank you!

::::: columns
::: {.column}
### Dylan Pieper

**University of Pittsburgh**

::: {style="font-size: 0.8em;"}
📧 djp119\@pitt.edu\
🦋 @dylanpieper.bsky.social\
💻 [github.com/dylanpieper](https://github.com/dylanpieper)
:::

### Questions?

*Let's discuss data!*
:::

::: {.column}
```{r}
#| fig-width: 4
#| fig-height: 4
#| fig-align: center
qrcode::qr_code("https://github.com/dylanpieper/posit-conf-2025") |> 
  plot(col = c("black", "white"))
```
:::
:::::